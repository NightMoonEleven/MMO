{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Лабораторная работа №5\n",
        "\n",
        "Курьянов А.И. группа ИУ5-21М\n",
        "\n",
        "Задание\n",
        "\n",
        "Для произвольного предложения или текста решите следующие задачи:\n",
        "\n",
        "1. Токенизация.\n",
        "2. Частеречная разметка.\n",
        "3. Лемматизация.\n",
        "4. Выделение (распознавание) именованных сущностей.\n",
        "5. Разбор предложения.\n",
        "\n",
        "Для произвольного набора данных, предназначенного для классификации текстов, решите задачу классификации текста двумя способами:\n",
        "\n",
        "  Способ 1. На основе CountVectorizer или TfidfVectorizer.\n",
        "\n",
        "  Способ 2. На основе моделей word2vec или Glove или fastText.\n",
        "Сравните качество полученных моделей."
      ],
      "metadata": {
        "id": "g44FhN4NjFmh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZpoo218Y2Ay"
      },
      "outputs": [],
      "source": [
        "text = '''И с каждой осенью я расцветаю вновь;\n",
        "Здоровью моему полезен русской холод;\n",
        "К привычкам бытия вновь чувствую любовь:\n",
        "Чредой слетает сон, чредой находит голод;\n",
        "Легко и радостно играет в сердце кровь,\n",
        "Желания кипят — я снова счастлив, молод,\n",
        "Я снова жизни полн — таков мой организм\n",
        "(Извольте мне простить ненужный прозаизм).'''\n",
        "text2 = '''И забываю мир — и в сладкой тишине\n",
        "Я сладко усыплен моим воображеньем,\n",
        "И пробуждается поэзия во мне:\n",
        "Душа стесняется лирическим волненьем,\n",
        "Трепещет и звучит, и ищет, как во сне,\n",
        "Излиться наконец свободным проявленьем —\n",
        "И тут ко мне идет незримый рой гостей,\n",
        "Знакомцы давние, плоды мечты моей.'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np693nsfbKDv",
        "outputId": "7cf2197e-3901-4a6b-c835-f1bac1a68882"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting natasha\n",
            "  Downloading natasha-1.4.0-py3-none-any.whl (34.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 34.4 MB 71 kB/s \n",
            "\u001b[?25hCollecting razdel>=0.5.0\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 1.6 MB/s \n",
            "\u001b[?25hCollecting ipymarkup>=0.8.0\n",
            "  Downloading ipymarkup-0.9.0-py3-none-any.whl (14 kB)\n",
            "Collecting navec>=0.9.0\n",
            "  Downloading navec-0.10.0-py3-none-any.whl (23 kB)\n",
            "Collecting yargy>=0.14.0\n",
            "  Downloading yargy-0.15.0-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 110 kB/s \n",
            "\u001b[?25hCollecting slovnet>=0.3.0\n",
            "  Downloading slovnet-0.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 4.6 MB/s \n",
            "\u001b[?25hCollecting intervaltree>=3\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from navec>=0.9.0->natasha) (1.21.6)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (0.6.2)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 41.4 MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Building wheels for collected packages: intervaltree\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26119 sha256=adfddabc2e0fc5a0f7be00e0569f4cc9d9f4bb099e10a77a2c9125f75e5e1d09\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/85/bd/1001cbb46dcfb71c2001cd7401c6fb250392f22a81ce3722f7\n",
            "Successfully built intervaltree\n",
            "Installing collected packages: pymorphy2-dicts-ru, dawg-python, razdel, pymorphy2, navec, intervaltree, yargy, slovnet, ipymarkup, natasha\n",
            "  Attempting uninstall: intervaltree\n",
            "    Found existing installation: intervaltree 2.1.0\n",
            "    Uninstalling intervaltree-2.1.0:\n",
            "      Successfully uninstalled intervaltree-2.1.0\n",
            "Successfully installed dawg-python-0.7.2 intervaltree-3.1.0 ipymarkup-0.9.0 natasha-1.4.0 navec-0.10.0 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844 razdel-0.5.0 slovnet-0.5.0 yargy-0.15.0\n"
          ]
        }
      ],
      "source": [
        "!pip install natasha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVSVMTxKi-Fd",
        "outputId": "4aa6f405-8bd2-4f80-f01d-e6ae8662eebb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: razdel in /usr/local/lib/python3.7/dist-packages (0.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install razdel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D29cTbU76Ef"
      },
      "source": [
        "#Задача токенизации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g976JvjQaEX-"
      },
      "outputs": [],
      "source": [
        "from razdel import tokenize, sentenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZ5RiWNraFGc",
        "outputId": "a36e84ff-5ac8-40ac-e623-85cab50118ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Substring(0, 1, 'И'),\n",
              " Substring(2, 3, 'с'),\n",
              " Substring(4, 10, 'каждой'),\n",
              " Substring(11, 17, 'осенью'),\n",
              " Substring(18, 19, 'я'),\n",
              " Substring(20, 29, 'расцветаю'),\n",
              " Substring(30, 35, 'вновь'),\n",
              " Substring(35, 36, ';'),\n",
              " Substring(37, 45, 'Здоровью'),\n",
              " Substring(46, 51, 'моему'),\n",
              " Substring(52, 59, 'полезен'),\n",
              " Substring(60, 67, 'русской'),\n",
              " Substring(68, 73, 'холод'),\n",
              " Substring(73, 74, ';'),\n",
              " Substring(75, 76, 'К'),\n",
              " Substring(77, 86, 'привычкам'),\n",
              " Substring(87, 92, 'бытия'),\n",
              " Substring(93, 98, 'вновь'),\n",
              " Substring(99, 107, 'чувствую'),\n",
              " Substring(108, 114, 'любовь'),\n",
              " Substring(114, 115, ':'),\n",
              " Substring(116, 122, 'Чредой'),\n",
              " Substring(123, 130, 'слетает'),\n",
              " Substring(131, 134, 'сон'),\n",
              " Substring(134, 135, ','),\n",
              " Substring(136, 142, 'чредой'),\n",
              " Substring(143, 150, 'находит'),\n",
              " Substring(151, 156, 'голод'),\n",
              " Substring(156, 157, ';'),\n",
              " Substring(158, 163, 'Легко'),\n",
              " Substring(164, 165, 'и'),\n",
              " Substring(166, 174, 'радостно'),\n",
              " Substring(175, 181, 'играет'),\n",
              " Substring(182, 183, 'в'),\n",
              " Substring(184, 190, 'сердце'),\n",
              " Substring(191, 196, 'кровь'),\n",
              " Substring(196, 197, ','),\n",
              " Substring(198, 205, 'Желания'),\n",
              " Substring(206, 211, 'кипят'),\n",
              " Substring(212, 213, '—'),\n",
              " Substring(214, 215, 'я'),\n",
              " Substring(216, 221, 'снова'),\n",
              " Substring(222, 230, 'счастлив'),\n",
              " Substring(230, 231, ','),\n",
              " Substring(232, 237, 'молод'),\n",
              " Substring(237, 238, ','),\n",
              " Substring(239, 240, 'Я'),\n",
              " Substring(241, 246, 'снова'),\n",
              " Substring(247, 252, 'жизни'),\n",
              " Substring(253, 257, 'полн'),\n",
              " Substring(258, 259, '—'),\n",
              " Substring(260, 265, 'таков'),\n",
              " Substring(266, 269, 'мой'),\n",
              " Substring(270, 278, 'организм'),\n",
              " Substring(279, 280, '('),\n",
              " Substring(280, 288, 'Извольте'),\n",
              " Substring(289, 292, 'мне'),\n",
              " Substring(293, 301, 'простить'),\n",
              " Substring(302, 310, 'ненужный'),\n",
              " Substring(311, 319, 'прозаизм'),\n",
              " Substring(319, 320, ')'),\n",
              " Substring(320, 321, '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "n_tok_text = list(tokenize(text))\n",
        "n_tok_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US4-R7DHaP2-",
        "outputId": "7fd49c8c-b573-46ea-f134-dbbdae1553a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['И',\n",
              " 'с',\n",
              " 'каждой',\n",
              " 'осенью',\n",
              " 'я',\n",
              " 'расцветаю',\n",
              " 'вновь',\n",
              " ';',\n",
              " 'Здоровью',\n",
              " 'моему',\n",
              " 'полезен',\n",
              " 'русской',\n",
              " 'холод',\n",
              " ';',\n",
              " 'К',\n",
              " 'привычкам',\n",
              " 'бытия',\n",
              " 'вновь',\n",
              " 'чувствую',\n",
              " 'любовь',\n",
              " ':',\n",
              " 'Чредой',\n",
              " 'слетает',\n",
              " 'сон',\n",
              " ',',\n",
              " 'чредой',\n",
              " 'находит',\n",
              " 'голод',\n",
              " ';',\n",
              " 'Легко',\n",
              " 'и',\n",
              " 'радостно',\n",
              " 'играет',\n",
              " 'в',\n",
              " 'сердце',\n",
              " 'кровь',\n",
              " ',',\n",
              " 'Желания',\n",
              " 'кипят',\n",
              " '—',\n",
              " 'я',\n",
              " 'снова',\n",
              " 'счастлив',\n",
              " ',',\n",
              " 'молод',\n",
              " ',',\n",
              " 'Я',\n",
              " 'снова',\n",
              " 'жизни',\n",
              " 'полн',\n",
              " '—',\n",
              " 'таков',\n",
              " 'мой',\n",
              " 'организм',\n",
              " '(',\n",
              " 'Извольте',\n",
              " 'мне',\n",
              " 'простить',\n",
              " 'ненужный',\n",
              " 'прозаизм',\n",
              " ')',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "[_.text for _ in n_tok_text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3qQdSq5aQqO",
        "outputId": "89edd790-7943-41d9-8e74-612ab0c5943b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Substring(0, 36, 'И с каждой осенью я расцветаю вновь;'),\n",
              " Substring(37, 74, 'Здоровью моему полезен русской холод;'),\n",
              " Substring(75,\n",
              "           157,\n",
              "           'К привычкам бытия вновь чувствую любовь:\\nЧредой слетает сон, чредой находит голод;'),\n",
              " Substring(158,\n",
              "           321,\n",
              "           'Легко и радостно играет в сердце кровь,\\nЖелания кипят — я снова счастлив, молод,\\nЯ снова жизни полн — таков мой организм\\n(Извольте мне простить ненужный прозаизм).')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "n_sen_text = list(sentenize(text))\n",
        "n_sen_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSsI-IsGjk9i",
        "outputId": "d6f3baff-4b88-4f6d-e842-25e7b3762bbb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['И с каждой осенью я расцветаю вновь;',\n",
              "  'Здоровью моему полезен русской холод;',\n",
              "  'К привычкам бытия вновь чувствую любовь:\\nЧредой слетает сон, чредой находит голод;',\n",
              "  'Легко и радостно играет в сердце кровь,\\nЖелания кипят — я снова счастлив, молод,\\nЯ снова жизни полн — таков мой организм\\n(Извольте мне простить ненужный прозаизм).'],\n",
              " 4)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "[_.text for _ in n_sen_text], len([_.text for _ in n_sen_text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-LaovsnjtZk"
      },
      "outputs": [],
      "source": [
        "# Этот вариант токенизации нужен для последующей обработки\n",
        "def n_sentenize(text):\n",
        "    n_sen_chunk = []\n",
        "    for sent in sentenize(text):\n",
        "        tokens = [_.text for _ in tokenize(sent.text)]\n",
        "        n_sen_chunk.append(tokens)\n",
        "    return n_sen_chunk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9y8VzzhjvHt",
        "outputId": "bd9001cf-52a4-47ee-83bc-d50d740ab6db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['И', 'с', 'каждой', 'осенью', 'я', 'расцветаю', 'вновь', ';'],\n",
              " ['Здоровью', 'моему', 'полезен', 'русской', 'холод', ';'],\n",
              " ['К',\n",
              "  'привычкам',\n",
              "  'бытия',\n",
              "  'вновь',\n",
              "  'чувствую',\n",
              "  'любовь',\n",
              "  ':',\n",
              "  'Чредой',\n",
              "  'слетает',\n",
              "  'сон',\n",
              "  ',',\n",
              "  'чредой',\n",
              "  'находит',\n",
              "  'голод',\n",
              "  ';'],\n",
              " ['Легко',\n",
              "  'и',\n",
              "  'радостно',\n",
              "  'играет',\n",
              "  'в',\n",
              "  'сердце',\n",
              "  'кровь',\n",
              "  ',',\n",
              "  'Желания',\n",
              "  'кипят',\n",
              "  '—',\n",
              "  'я',\n",
              "  'снова',\n",
              "  'счастлив',\n",
              "  ',',\n",
              "  'молод',\n",
              "  ',',\n",
              "  'Я',\n",
              "  'снова',\n",
              "  'жизни',\n",
              "  'полн',\n",
              "  '—',\n",
              "  'таков',\n",
              "  'мой',\n",
              "  'организм',\n",
              "  '(',\n",
              "  'Извольте',\n",
              "  'мне',\n",
              "  'простить',\n",
              "  'ненужный',\n",
              "  'прозаизм',\n",
              "  ')',\n",
              "  '.']]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "n_sen_chunk = n_sentenize(text)\n",
        "n_sen_chunk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zn4MxoHwocQ8",
        "outputId": "c0bac354-65bb-4bf1-bd3a-0167a588d693"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['И',\n",
              "  'забываю',\n",
              "  'мир',\n",
              "  '—',\n",
              "  'и',\n",
              "  'в',\n",
              "  'сладкой',\n",
              "  'тишине',\n",
              "  'Я',\n",
              "  'сладко',\n",
              "  'усыплен',\n",
              "  'моим',\n",
              "  'воображеньем',\n",
              "  ',',\n",
              "  'И',\n",
              "  'пробуждается',\n",
              "  'поэзия',\n",
              "  'во',\n",
              "  'мне',\n",
              "  ':',\n",
              "  'Душа',\n",
              "  'стесняется',\n",
              "  'лирическим',\n",
              "  'волненьем',\n",
              "  ',',\n",
              "  'Трепещет',\n",
              "  'и',\n",
              "  'звучит',\n",
              "  ',',\n",
              "  'и',\n",
              "  'ищет',\n",
              "  ',',\n",
              "  'как',\n",
              "  'во',\n",
              "  'сне',\n",
              "  ',',\n",
              "  'Излиться',\n",
              "  'наконец',\n",
              "  'свободным',\n",
              "  'проявленьем',\n",
              "  '—',\n",
              "  'И',\n",
              "  'тут',\n",
              "  'ко',\n",
              "  'мне',\n",
              "  'идет',\n",
              "  'незримый',\n",
              "  'рой',\n",
              "  'гостей',\n",
              "  ',',\n",
              "  'Знакомцы',\n",
              "  'давние',\n",
              "  ',',\n",
              "  'плоды',\n",
              "  'мечты',\n",
              "  'моей',\n",
              "  '.']]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "n_sen_chunk_2 = n_sentenize(text2)\n",
        "n_sen_chunk_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWPyU6o68IxP"
      },
      "source": [
        "#Частеречная разметка"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJ5AC_rBj7Au"
      },
      "outputs": [],
      "source": [
        "from navec import Navec\n",
        "from slovnet import Morph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnUNaqiGj9x4"
      },
      "outputs": [],
      "source": [
        "# Файл необходимо скачать по ссылке https://github.com/natasha/navec#downloads\n",
        "navec = Navec.load('navec_news_v1_1B_250K_300d_100q.tar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIbJX44Ck5TR"
      },
      "outputs": [],
      "source": [
        "# Файл необходимо скачать по ссылке https://github.com/natasha/slovnet#downloads\n",
        "n_morph = Morph.load('slovnet_morph_news_v1.tar', batch_size=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGmz2S2OlB-x"
      },
      "outputs": [],
      "source": [
        "morph_res = n_morph.navec(navec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHeplM8slDbu"
      },
      "outputs": [],
      "source": [
        "def print_pos(markup):\n",
        "    for token in markup.tokens:\n",
        "        print('{} - {}'.format(token.text, token.tag))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox7jury8lGBs",
        "outputId": "da9e6d7c-a75b-47b6-d890-472a44d86636"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "И - CCONJ\n",
            "с - ADP\n",
            "каждой - DET|Case=Ins|Gender=Fem|Number=Sing\n",
            "осенью - NOUN|Animacy=Inan|Case=Ins|Gender=Fem|Number=Sing\n",
            "я - PRON|Case=Nom|Number=Sing|Person=1\n",
            "расцветаю - VERB|Aspect=Imp|Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin|Voice=Act\n",
            "вновь - ADV|Degree=Pos\n",
            "; - PUNCT\n",
            "Здоровью - NOUN|Animacy=Inan|Case=Dat|Gender=Neut|Number=Sing\n",
            "моему - DET|Case=Dat|Gender=Neut|Number=Sing\n",
            "полезен - ADJ|Degree=Pos|Gender=Masc|Number=Sing|Variant=Short\n",
            "русской - ADJ|Case=Nom|Degree=Pos|Gender=Masc|Number=Sing\n",
            "холод - NOUN|Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing\n",
            "; - PUNCT\n",
            "К - ADP\n",
            "привычкам - NOUN|Animacy=Inan|Case=Dat|Gender=Masc|Number=Plur\n",
            "бытия - NOUN|Animacy=Inan|Case=Gen|Gender=Neut|Number=Sing\n",
            "вновь - ADV|Degree=Pos\n",
            "чувствую - VERB|Aspect=Imp|Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin|Voice=Act\n",
            "любовь - NOUN|Animacy=Inan|Case=Acc|Gender=Fem|Number=Sing\n",
            ": - PUNCT\n",
            "Чредой - PROPN|Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing\n",
            "слетает - VERB|Aspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\n",
            "сон - NOUN|Animacy=Inan|Case=Acc|Gender=Masc|Number=Sing\n",
            ", - PUNCT\n",
            "чредой - NOUN|Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing\n",
            "находит - VERB|Aspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\n",
            "голод - NOUN|Animacy=Inan|Case=Acc|Gender=Masc|Number=Sing\n",
            "; - PUNCT\n",
            "Легко - ADV|Degree=Pos\n",
            "и - CCONJ\n",
            "радостно - ADV|Degree=Pos\n",
            "играет - VERB|Aspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\n",
            "в - ADP\n",
            "сердце - NOUN|Animacy=Inan|Case=Acc|Gender=Neut|Number=Sing\n",
            "кровь - NOUN|Animacy=Inan|Case=Acc|Gender=Fem|Number=Sing\n",
            ", - PUNCT\n",
            "Желания - NOUN|Animacy=Inan|Case=Nom|Gender=Neut|Number=Plur\n",
            "кипят - VERB|Aspect=Imp|Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin|Voice=Mid\n",
            "— - PUNCT\n",
            "я - PRON|Case=Nom|Number=Sing|Person=1\n",
            "снова - ADV|Degree=Pos\n",
            "счастлив - ADJ|Degree=Pos|Gender=Masc|Number=Sing|Variant=Short\n",
            ", - PUNCT\n",
            "молод - ADJ|Degree=Pos|Gender=Masc|Number=Sing|Variant=Short\n",
            ", - PUNCT\n",
            "Я - PRON|Case=Nom|Number=Sing|Person=1\n",
            "снова - ADV|Degree=Pos\n",
            "жизни - NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing\n",
            "полн - NOUN|Animacy=Anim|Case=Gen|Gender=Masc|Number=Plur\n",
            "— - PUNCT\n",
            "таков - ADJ|Degree=Pos|Gender=Masc|Number=Sing|Variant=Short\n",
            "мой - DET|Case=Nom|Gender=Masc|Number=Sing\n",
            "организм - NOUN|Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing\n",
            "( - PUNCT\n",
            "Извольте - VERB|Aspect=Imp|Mood=Imp|Number=Plur|Person=2|VerbForm=Fin|Voice=Act\n",
            "мне - PRON|Case=Dat|Number=Sing|Person=1\n",
            "простить - VERB|Aspect=Perf|VerbForm=Inf|Voice=Act\n",
            "ненужный - ADJ|Animacy=Inan|Case=Acc|Degree=Pos|Gender=Masc|Number=Sing\n",
            "прозаизм - NOUN|Animacy=Inan|Case=Acc|Gender=Masc|Number=Sing\n",
            ") - PUNCT\n",
            ". - PUNCT\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None, None]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "n_text_markup = list(_ for _ in n_morph.map(n_sen_chunk))\n",
        "[print_pos(x) for x in n_text_markup]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lR8begRoh2Y",
        "outputId": "4aeaa44c-3901-4b09-b1db-c926a5937652"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "И - CCONJ\n",
            "забываю - VERB|Aspect=Imp|Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin|Voice=Act\n",
            "мир - NOUN|Animacy=Inan|Case=Acc|Gender=Masc|Number=Sing\n",
            "— - PUNCT\n",
            "и - CCONJ\n",
            "в - ADP\n",
            "сладкой - ADJ|Case=Loc|Degree=Pos|Gender=Fem|Number=Sing\n",
            "тишине - NOUN|Animacy=Inan|Case=Loc|Gender=Fem|Number=Sing\n",
            "Я - PRON|Case=Nom|Number=Sing|Person=1\n",
            "сладко - ADV|Degree=Pos\n",
            "усыплен - VERB|Aspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\n",
            "моим - DET|Case=Ins|Gender=Masc|Number=Sing\n",
            "воображеньем - NOUN|Animacy=Inan|Case=Ins|Gender=Masc|Number=Sing\n",
            ", - PUNCT\n",
            "И - CCONJ\n",
            "пробуждается - VERB|Aspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\n",
            "поэзия - NOUN|Animacy=Inan|Case=Nom|Gender=Fem|Number=Sing\n",
            "во - ADP\n",
            "мне - PRON|Case=Loc|Number=Sing|Person=1\n",
            ": - PUNCT\n",
            "Душа - PROPN|Animacy=Anim|Case=Nom|Gender=Fem|Number=Sing\n",
            "стесняется - VERB|Aspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Mid\n",
            "лирическим - ADJ|Case=Ins|Degree=Pos|Gender=Masc|Number=Sing\n",
            "волненьем - NOUN|Animacy=Inan|Case=Ins|Gender=Masc|Number=Sing\n",
            ", - PUNCT\n",
            "Трепещет - PROPN|Animacy=Anim|Case=Ins|Gender=Masc|Number=Sing\n",
            "и - CCONJ\n",
            "звучит - VERB|Aspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\n",
            ", - PUNCT\n",
            "и - CCONJ\n",
            "ищет - VERB|Aspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\n",
            ", - PUNCT\n",
            "как - SCONJ\n",
            "во - ADP\n",
            "сне - NOUN|Animacy=Inan|Case=Loc|Gender=Masc|Number=Sing\n",
            ", - PUNCT\n",
            "Излиться - PROPN|Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing\n",
            "наконец - ADV|Degree=Pos\n",
            "свободным - ADJ|Case=Ins|Degree=Pos|Gender=Masc|Number=Sing\n",
            "проявленьем - NOUN|Animacy=Inan|Case=Ins|Gender=Masc|Number=Sing\n",
            "— - PUNCT\n",
            "И - CCONJ\n",
            "тут - ADV|Degree=Pos\n",
            "ко - ADP\n",
            "мне - PRON|Case=Dat|Number=Sing|Person=1\n",
            "идет - VERB|Aspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\n",
            "незримый - ADJ|Case=Nom|Degree=Pos|Gender=Masc|Number=Sing\n",
            "рой - NOUN|Animacy=Anim|Case=Gen|Gender=Fem|Number=Plur\n",
            "гостей - NOUN|Animacy=Anim|Case=Gen|Gender=Masc|Number=Plur\n",
            ", - PUNCT\n",
            "Знакомцы - PROPN|Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing\n",
            "давние - ADJ|Case=Nom|Degree=Pos|Number=Plur\n",
            ", - PUNCT\n",
            "плоды - NOUN|Animacy=Inan|Case=Nom|Gender=Masc|Number=Plur\n",
            "мечты - NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing\n",
            "моей - DET|Case=Gen|Gender=Fem|Number=Sing\n",
            ". - PUNCT\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "n_text2_markup = list(n_morph.map(n_sen_chunk_2))\n",
        "[print_pos(x) for x in n_text2_markup]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0okcggK8RyX"
      },
      "source": [
        "#Лемматизация"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwcHLMPxlZbv"
      },
      "outputs": [],
      "source": [
        "from natasha import Doc, Segmenter, NewsEmbedding, NewsMorphTagger, MorphVocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiZyPQqClbSu"
      },
      "outputs": [],
      "source": [
        "def n_lemmatize(text):\n",
        "    emb = NewsEmbedding()\n",
        "    morph_tagger = NewsMorphTagger(emb)\n",
        "    segmenter = Segmenter()\n",
        "    morph_vocab = MorphVocab()\n",
        "    doc = Doc(text)\n",
        "    doc.segment(segmenter)\n",
        "    doc.tag_morph(morph_tagger)\n",
        "    for token in doc.tokens:\n",
        "        token.lemmatize(morph_vocab)\n",
        "    return doc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_vfR7milc_L",
        "outputId": "4c48a1f9-48a7-43c7-f493-ab930dda7e20"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'(': '(',\n",
              " ')': ')',\n",
              " ',': ',',\n",
              " '.': '.',\n",
              " ':': ':',\n",
              " ';': ';',\n",
              " 'Желания': 'желание',\n",
              " 'Здоровью': 'здоровье',\n",
              " 'И': 'и',\n",
              " 'Извольте': 'изволить',\n",
              " 'К': 'к',\n",
              " 'Легко': 'легко',\n",
              " 'Чредой': 'чреда',\n",
              " 'Я': 'я',\n",
              " 'бытия': 'бытие',\n",
              " 'в': 'в',\n",
              " 'вновь': 'вновь',\n",
              " 'голод': 'голод',\n",
              " 'жизни': 'жизнь',\n",
              " 'и': 'и',\n",
              " 'играет': 'играть',\n",
              " 'каждой': 'каждый',\n",
              " 'кипят': 'кипеть',\n",
              " 'кровь': 'кровь',\n",
              " 'любовь': 'любовь',\n",
              " 'мне': 'я',\n",
              " 'моему': 'мой',\n",
              " 'мой': 'мой',\n",
              " 'молод': 'молодой',\n",
              " 'находит': 'находить',\n",
              " 'ненужный': 'ненужный',\n",
              " 'организм': 'организм',\n",
              " 'осенью': 'осень',\n",
              " 'полезен': 'полезный',\n",
              " 'полн': 'полна',\n",
              " 'привычкам': 'привычка',\n",
              " 'прозаизм': 'прозаизм',\n",
              " 'простить': 'простить',\n",
              " 'радостно': 'радостно',\n",
              " 'расцветаю': 'расцветать',\n",
              " 'русской': 'русский',\n",
              " 'с': 'с',\n",
              " 'сердце': 'сердце',\n",
              " 'слетает': 'слетать',\n",
              " 'снова': 'снова',\n",
              " 'сон': 'сон',\n",
              " 'счастлив': 'счастливый',\n",
              " 'таков': 'таков',\n",
              " 'холод': 'холод',\n",
              " 'чредой': 'чреда',\n",
              " 'чувствую': 'чувствовать',\n",
              " 'я': 'я',\n",
              " '—': '—'}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "n_doc = n_lemmatize(text)\n",
        "{_.text: _.lemma for _ in n_doc.tokens}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctQlhapPoooX",
        "outputId": "26210bff-53e3-4621-c481-4cb35410abfc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{',': ',',\n",
              " '.': '.',\n",
              " ':': ':',\n",
              " 'Душа': 'душа',\n",
              " 'Знакомцы': 'знакомец',\n",
              " 'И': 'и',\n",
              " 'Излиться': 'излиться',\n",
              " 'Трепещет': 'трепетать',\n",
              " 'Я': 'я',\n",
              " 'в': 'в',\n",
              " 'во': 'в',\n",
              " 'волненьем': 'волнение',\n",
              " 'воображеньем': 'воображение',\n",
              " 'гостей': 'гость',\n",
              " 'давние': 'давний',\n",
              " 'забываю': 'забывать',\n",
              " 'звучит': 'звучать',\n",
              " 'и': 'и',\n",
              " 'идет': 'идти',\n",
              " 'ищет': 'искать',\n",
              " 'как': 'как',\n",
              " 'ко': 'к',\n",
              " 'лирическим': 'лирический',\n",
              " 'мечты': 'мечта',\n",
              " 'мир': 'мир',\n",
              " 'мне': 'я',\n",
              " 'моей': 'мой',\n",
              " 'моим': 'мой',\n",
              " 'наконец': 'наконец',\n",
              " 'незримый': 'незримый',\n",
              " 'плоды': 'плод',\n",
              " 'поэзия': 'поэзия',\n",
              " 'пробуждается': 'пробуждаться',\n",
              " 'проявленьем': 'проявление',\n",
              " 'рой': 'рой',\n",
              " 'свободным': 'свободный',\n",
              " 'сладко': 'сладко',\n",
              " 'сладкой': 'сладкий',\n",
              " 'сне': 'сон',\n",
              " 'стесняется': 'стесняться',\n",
              " 'тишине': 'тишина',\n",
              " 'тут': 'тут',\n",
              " 'усыплен': 'усыпить',\n",
              " '—': '—'}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "n_doc2 = n_lemmatize(text2)\n",
        "{_.text: _.lemma for _ in n_doc2.tokens}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGiHQ5nV8YHS"
      },
      "source": [
        "# Выделение (распознавание) именованных сущностей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CX1Jn2LjllO4"
      },
      "outputs": [],
      "source": [
        "from slovnet import NER\n",
        "from ipymarkup import show_span_ascii_markup as show_markup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jR1CB3clmoO"
      },
      "outputs": [],
      "source": [
        "ner = NER.load('slovnet_ner_news_v1.tar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfcXKkyLlo_f"
      },
      "outputs": [],
      "source": [
        "ner_res = ner.navec(navec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUkgF6nVlrLY",
        "outputId": "fe1c5db9-edef-4888-ff50-de8fc5faa29f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SpanMarkup(\n",
              "    text='И забываю мир — и в сладкой тишине\\nЯ сладко усыплен моим воображеньем,\\nИ пробуждается поэзия во мне:\\nДуша стесняется лирическим волненьем,\\nТрепещет и звучит, и ищет, как во сне,\\nИзлиться наконец свободным проявленьем —\\nИ тут ко мне идет незримый рой гостей,\\nЗнакомцы давние, плоды мечты моей.',\n",
              "    spans=[Span(\n",
              "         start=139,\n",
              "         stop=147,\n",
              "         type='PER'\n",
              "     ), Span(\n",
              "         start=178,\n",
              "         stop=186,\n",
              "         type='PER'\n",
              "     ), Span(\n",
              "         start=258,\n",
              "         stop=266,\n",
              "         type='PER'\n",
              "     )]\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "markup_ner = ner(text2)\n",
        "markup_ner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iy-71aTplrGm",
        "outputId": "02572194-147f-4784-e9d6-a45e1893c40e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "И забываю мир — и в сладкой тишине\n",
            "Я сладко усыплен моим воображеньем,\n",
            "И пробуждается поэзия во мне:\n",
            "Душа стесняется лирическим волненьем,\n",
            "Трепещет и звучит, и ищет, как во сне,\n",
            "PER─────                              \n",
            "Излиться наконец свободным проявленьем —\n",
            "PER─────                                \n",
            "И тут ко мне идет незримый рой гостей,\n",
            "Знакомцы давние, плоды мечты моей.\n",
            "PER─────                          \n"
          ]
        }
      ],
      "source": [
        "show_markup(markup_ner.text, markup_ner.spans)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1EEBFmk8ddx"
      },
      "source": [
        "#Разбор предложения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w07LI_cdnt3A"
      },
      "outputs": [],
      "source": [
        "from natasha import NewsSyntaxParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ad3aEUqunyFr"
      },
      "outputs": [],
      "source": [
        "emb = NewsEmbedding()\n",
        "syntax_parser = NewsSyntaxParser(emb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbFuGGMinzZu",
        "outputId": "09063b57-3add-4442-a1ff-ebb3f3221827"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "┌──────► И         cc\n",
            "│   ┌──► с         case\n",
            "│   │ ┌► каждой    det\n",
            "│ ┌►└─└─ осенью    obl\n",
            "│ │   ┌► я         nsubj\n",
            "└─└─┌─└─ расцветаю \n",
            "│   └──► вновь     advmod\n",
            "└──────► ;         punct\n"
          ]
        }
      ],
      "source": [
        "n_doc.parse_syntax(syntax_parser)\n",
        "n_doc.sents[0].syntax.print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc4OlSa1n08h",
        "outputId": "822fef08-5b59-4b4a-d129-8855353a6686"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ┌──► Здоровью nsubj\n",
            "    │ ┌► моему    iobj\n",
            "┌─┌─└─└─ полезен  \n",
            "│ │   ┌► русской  amod\n",
            "│ └──►└─ холод    nsubj\n",
            "└──────► ;        punct\n"
          ]
        }
      ],
      "source": [
        "n_doc.parse_syntax(syntax_parser)\n",
        "n_doc.sents[1].syntax.print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7a2nHbUn9-4",
        "outputId": "071d01f9-ffdd-42b2-bba2-bb96f8b8e277"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        ┌► К         case\n",
            "    ┌►┌─└─ привычкам obl\n",
            "    │ └──► бытия     nmod\n",
            "    │   ┌► вновь     advmod\n",
            "┌─┌─└─┌─└─ чувствую  \n",
            "│ │ ┌─└──► любовь    obj\n",
            "│ │ │   ┌► :         punct\n",
            "│ │ │ ┌►│  Чредой    amod\n",
            "│ │ └►│ └─ слетает   parataxis\n",
            "│ │   └─└► сон       obj\n",
            "│ │   ┌──► ,         punct\n",
            "│ │   │ ┌► чредой    nsubj\n",
            "│ └──►└─└─ находит   parataxis\n",
            "│     └──► голод     obj\n",
            "└────────► ;         punct\n"
          ]
        }
      ],
      "source": [
        "n_doc.parse_syntax(syntax_parser)\n",
        "n_doc.sents[2].syntax.print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QcEdIjQoEX9",
        "outputId": "891a12e9-38c9-4d12-da2a-42328704c698"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        ┌► И            cc\n",
            "┌─────────┌───────────────┌───────────┌─└─ забываю      \n",
            "│         │               │           └──► мир          obj\n",
            "│         │   ┌──────────►│                —            punct\n",
            "│         │   │           │         ┌────► и            cc\n",
            "│         │   │           │         │ ┌──► в            case\n",
            "│         │   │           │         │ │ ┌► сладкой      amod\n",
            "│         │ ┌►│           │         └─└─└─ тишине       conj\n",
            "│         │ │ │           │   ┌──────────► Я            nsubj\n",
            "│         │ │ │           │ ┌─│            сладко       \n",
            "│   ┌───┌─│ │ │   ┌─┌──►┌─│ │ │     ┌─┌─── усыплен      ccomp\n",
            "│   │   │ │ │ │   │ │   │ │ │ │     │ │ ┌► моим         det\n",
            "│   │   │ │ │ │   │ │   │ │ │ │ ┌───│ └►└─ воображеньем iobj\n",
            "│   │   │ │ │ │   │ │ ┌►│ │ │ │ │   │      ,            punct\n",
            "│   │   │ │ │ │   │ │ │ │ │ │ │ │   └────► И            cc\n",
            "│   │   │ │ │ │   │ │ │ │ │ │ │ │       ┌► пробуждается amod\n",
            "│ ┌─│ ┌─│ │ │ │   │ │ │ │ └►│ │ │     ┌─└─ поэзия       nsubj\n",
            "│ │ │ │ │ │ │ │   │ │ │ │   │ │ │     │ ┌► во           case\n",
            "│ │ │ │ │ │ │ │   │ │ │ │   │ │ │     └►└─ мне          nmod\n",
            "│ │ │ │ │ │ │ │   │ │ │ │   │ │ │     ┌──► :            punct\n",
            "│ │ │ │ │ │ │ │   │ │ │ │   │ │ │     │ ┌► Душа         nsubj\n",
            "│ │ │ │ │ │ │ │ ┌─│ │ │ │   │ └─│ ┌──►└─└─ стесняется   ccomp\n",
            "│ │ │ │ │ │ │ │ │ │ │ │ │   │   └►│        лирическим   amod\n",
            "│ │ │ │ │ │ │ │ │ │ │ │ │   └────►│   ┌─── волненьем    obl\n",
            "│ │ │ │ │ │ │ │ │ │ │ │ │         │   │ ┌► ,            punct\n",
            "│ │ │ │ │ │ │ │ │ │ │ │ │         │   └►└─ Трепещет     conj\n",
            "│ │ │ │ │ │ │ │ │ │ │ │ │         │ ┌────► и            cc\n",
            "│ │ │ │ │ │ │ │ │ │ │ │ └────────►│ │      звучит       conj\n",
            "│ │ │ │ │ │ │ │ │ │ │ │           │ │ ┌──► ,            punct\n",
            "│ │ │ │ │ │ │ │ │ │ │ │           │ │ │ ┌► и            cc\n",
            "│ │ │ │ │ └►│ └─│ │ └─└───────┌─┌─└─└─└─└─ ищет         conj\n",
            "│ │ │ │ │   │   │ │           │ │ │ ┌────► ,            punct\n",
            "│ │ │ │ │   │   │ │           │ │ │ │ ┌──► как          case\n",
            "│ │ │ │ │   │   │ │           │ │ │ │ │ ┌► во           case\n",
            "│ │ │ │ │   └───│ │         ┌─│ │ └►└─└─└─ сне          obl\n",
            "│ │ │ │ │       │ │         │ │ │     └──► ,            punct\n",
            "│ │ │ │ │       │ └────────►│ │ │          Излиться     nsubj\n",
            "│ │ │ │ │       │           │ │ │          наконец      \n",
            "│ │ │ │ │       │           │ │ │       ┌► свободным    amod\n",
            "│ │ │ │ └──────►│           │ │ │       └─ проявленьем  iobj\n",
            "│ │ │ │         │           │ │ └────────► —            punct\n",
            "│ │ │ │         │           │ └──────────► И            cc\n",
            "│ │ │ │         │           │       ┌────► тут          advmod\n",
            "│ │ │ │         │           │       │   ┌► ко           case\n",
            "│ │ │ │         │           │       │ ┌►└─ мне          obl\n",
            "│ │ └►│         │           │       └─└─── идет         conj\n",
            "│ │   │         │           │           ┌► незримый     amod\n",
            "│ │   │         └──────────►│         ┌─└─ рой          obj\n",
            "│ │   │                     │         └──► гостей       nmod\n",
            "│ │   │                     └────────────► ,            punct\n",
            "│ │   └──────────────────────────────────► Знакомцы     amod\n",
            "│ └──────────────────────────────────►┌─── давние       amod\n",
            "│                                     │ ┌► ,            punct\n",
            "│                                     └►└─ плоды        conj\n",
            "│                                       ┌─ мечты        \n",
            "│                                       └► моей         det\n",
            "└────────────────────────────────────────► .            punct\n"
          ]
        }
      ],
      "source": [
        "n_doc2.parse_syntax(syntax_parser)\n",
        "n_doc2.sents[0].syntax.print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-c2XPKKOq7Wu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Dict, Tuple\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, median_absolute_error, r2_score \n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline \n",
        "sns.set(style=\"ticks\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAzmgaJ_80sH"
      },
      "source": [
        "# Векторизация текста на основе модели \"мешка слов\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLoXLDqzq4Ku"
      },
      "outputs": [],
      "source": [
        "categories = [\"rec.motorcycles\", \"rec.sport.baseball\", \"sci.electronics\",\"sci.med\"]\n",
        "newsgroups = fetch_20newsgroups(subset='train', categories=categories)\n",
        "data = newsgroups['data']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42Wh-CynrkGj"
      },
      "outputs": [],
      "source": [
        "def accuracy_score_for_classes(\n",
        "    y_true: np.ndarray, \n",
        "    y_pred: np.ndarray) -> Dict[int, float]:\n",
        "    \"\"\"\n",
        "    Вычисление метрики accuracy для каждого класса\n",
        "    y_true - истинные значения классов\n",
        "    y_pred - предсказанные значения классов\n",
        "    Возвращает словарь: ключ - метка класса, \n",
        "    значение - Accuracy для данного класса\n",
        "    \"\"\"\n",
        "    # Для удобства фильтрации сформируем Pandas DataFrame \n",
        "    d = {'t': y_true, 'p': y_pred}\n",
        "    df = pd.DataFrame(data=d)\n",
        "    # Метки классов\n",
        "    classes = np.unique(y_true)\n",
        "    # Результирующий словарь\n",
        "    res = dict()\n",
        "    # Перебор меток классов\n",
        "    for c in classes:\n",
        "        # отфильтруем данные, которые соответствуют \n",
        "        # текущей метке класса в истинных значениях\n",
        "        temp_data_flt = df[df['t']==c]\n",
        "        # расчет accuracy для заданной метки класса\n",
        "        temp_acc = accuracy_score(\n",
        "            temp_data_flt['t'].values, \n",
        "            temp_data_flt['p'].values)\n",
        "        # сохранение результата в словарь\n",
        "        res[c] = temp_acc\n",
        "    return res\n",
        "\n",
        "def print_accuracy_score_for_classes(\n",
        "    y_true: np.ndarray, \n",
        "    y_pred: np.ndarray):\n",
        "    \"\"\"\n",
        "    Вывод метрики accuracy для каждого класса\n",
        "    \"\"\"\n",
        "    accs = accuracy_score_for_classes(y_true, y_pred)\n",
        "    if len(accs)>0:\n",
        "        print('Метка \\t Accuracy')\n",
        "    for i in accs:\n",
        "        print('{} \\t {}'.format(i, accs[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esrSY6qXrleU",
        "outputId": "a3709131-1542-47e3-87bd-a036d469d5f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество сформированных признаков - 33448\n"
          ]
        }
      ],
      "source": [
        "vocabVect = CountVectorizer()\n",
        "vocabVect.fit(data)\n",
        "corpusVocab = vocabVect.vocabulary_\n",
        "print('Количество сформированных признаков - {}'.format(len(corpusVocab)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UA7wvzZsJxl",
        "outputId": "5854abae-ce3d-4440-ac3a-c94c8b346472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nrmendel=22213\n",
            "unix=31462\n",
            "amherst=5287\n",
            "edu=12444\n",
            "nathaniel=21624\n",
            "mendell=20477\n",
            "subject=29220\n",
            "re=25369\n",
            "bike=6898\n"
          ]
        }
      ],
      "source": [
        "for i in list(corpusVocab)[1:10]:\n",
        "    print('{}={}'.format(i, corpusVocab[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_MD1mfu9BUt"
      },
      "source": [
        "# Использование класса CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOcZ0afBs98g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0549b54-1b8c-4c52-b41f-1cb604b5fe26"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<2380x33448 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 335176 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "test_features = vocabVect.transform(data)\n",
        "test_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olYUOhsstEZ1",
        "outputId": "a034b78e-287c-4ce5-accd-201f62af6484"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [2, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "test_features.todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-56OfvNtH9r",
        "outputId": "aa65b7fe-d4cb-4517-fe16-2216a5b2e6c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33448"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "# Размер нулевой строки\n",
        "len(test_features.todense()[0].getA1())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lQND6-DtKEh",
        "outputId": "a7e34e9b-cde1-4cd1-a583-520c47cb8759"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2]\n"
          ]
        }
      ],
      "source": [
        "# Непустые значения нулевой строки\n",
        "print([i for i in test_features.todense()[0].getA1() if i>0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZMU_R7GtS6d",
        "outputId": "6f25950e-3e2b-4c5c-9b28-1983d5d3114a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['00',\n",
              " '000',\n",
              " '0000',\n",
              " '0000000004',\n",
              " '0000000005',\n",
              " '0000000667',\n",
              " '0000001200',\n",
              " '0001',\n",
              " '00014',\n",
              " '0002']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "vocabVect.get_feature_names()[0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsJo3ST09MHT"
      },
      "source": [
        "# Решение задачи анализа тональности текста на основе модели \"мешка слов\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VV9Gdq0At4yY"
      },
      "outputs": [],
      "source": [
        "def VectorizeAndClassify(vectorizers_list, classifiers_list):\n",
        "    for v in vectorizers_list:\n",
        "        for c in classifiers_list:\n",
        "            pipeline1 = Pipeline([(\"vectorizer\", v), (\"classifier\", c)])\n",
        "            score = cross_val_score(pipeline1, newsgroups['data'], newsgroups['target'], scoring='accuracy', cv=3).mean()\n",
        "            print('Векторизация - {}'.format(v))\n",
        "            print('Модель для классификации - {}'.format(c))\n",
        "            print('Accuracy = {}'.format(score))\n",
        "            print('===========================')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdDlkVmyt9uu",
        "outputId": "11a8c750-bdc2-4f31-da58-72e35ffdb67e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '0000': 2, '0000000004': 3,\n",
            "                            '0000000005': 4, '0000000667': 5, '0000001200': 6,\n",
            "                            '0001': 7, '00014': 8, '0002': 9, '0003': 10,\n",
            "                            '0005111312': 11, '0005111312na1em': 12,\n",
            "                            '00072': 13, '000851': 14, '000rpm': 15,\n",
            "                            '000th': 16, '001': 17, '0010': 18, '001004': 19,\n",
            "                            '0011': 20, '001211': 21, '0013': 22, '001642': 23,\n",
            "                            '001813': 24, '002': 25, '002222': 26,\n",
            "                            '002251w': 27, '0023': 28, '002937': 29, ...})\n",
            "Модель для классификации - LogisticRegression(C=3.0)\n",
            "Accuracy = 0.937813339432037\n",
            "===========================\n",
            "Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '0000': 2, '0000000004': 3,\n",
            "                            '0000000005': 4, '0000000667': 5, '0000001200': 6,\n",
            "                            '0001': 7, '00014': 8, '0002': 9, '0003': 10,\n",
            "                            '0005111312': 11, '0005111312na1em': 12,\n",
            "                            '00072': 13, '000851': 14, '000rpm': 15,\n",
            "                            '000th': 16, '001': 17, '0010': 18, '001004': 19,\n",
            "                            '0011': 20, '001211': 21, '0013': 22, '001642': 23,\n",
            "                            '001813': 24, '002': 25, '002222': 26,\n",
            "                            '002251w': 27, '0023': 28, '002937': 29, ...})\n",
            "Модель для классификации - LinearSVC()\n",
            "Accuracy = 0.9453742497059174\n",
            "===========================\n",
            "Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '0000': 2, '0000000004': 3,\n",
            "                            '0000000005': 4, '0000000667': 5, '0000001200': 6,\n",
            "                            '0001': 7, '00014': 8, '0002': 9, '0003': 10,\n",
            "                            '0005111312': 11, '0005111312na1em': 12,\n",
            "                            '00072': 13, '000851': 14, '000rpm': 15,\n",
            "                            '000th': 16, '001': 17, '0010': 18, '001004': 19,\n",
            "                            '0011': 20, '001211': 21, '0013': 22, '001642': 23,\n",
            "                            '001813': 24, '002': 25, '002222': 26,\n",
            "                            '002251w': 27, '0023': 28, '002937': 29, ...})\n",
            "Модель для классификации - KNeighborsClassifier()\n",
            "Accuracy = 0.6655358653541747\n",
            "===========================\n"
          ]
        }
      ],
      "source": [
        "vectorizers_list = [CountVectorizer(vocabulary = corpusVocab)]\n",
        "classifiers_list = [LogisticRegression(C=3.0), LinearSVC(), KNeighborsClassifier()]\n",
        "VectorizeAndClassify(vectorizers_list, classifiers_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2mfQKgl9RN3"
      },
      "source": [
        "# Разделим выборку на обучающую и тестовую и проверим решение для лучшей модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m77McUr1uylj"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(newsgroups['data'], newsgroups['target'], test_size=0.5, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7g6e4RKBvIHn"
      },
      "outputs": [],
      "source": [
        "def sentiment(v, c):\n",
        "    model = Pipeline(\n",
        "        [(\"vectorizer\", v), \n",
        "         (\"classifier\", c)])\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print_accuracy_score_for_classes(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcvoZrEgvFRk",
        "outputId": "0628c0a9-0cdc-4353-f02b-3a466b6a1391"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Метка \t Accuracy\n",
            "0 \t 0.9290322580645162\n",
            "1 \t 0.9675090252707581\n",
            "2 \t 0.9026845637583892\n",
            "3 \t 0.9245901639344263\n"
          ]
        }
      ],
      "source": [
        "sentiment(CountVectorizer(), LinearSVC())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8gze-2y9bRl"
      },
      "source": [
        "# Работа с векторными представлениями слов с использованием word2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7Y1WfrRwAWR"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from gensim.models import word2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afSGkgfli-Fz",
        "outputId": "9b347e15-e69f-4f8d-b93d-9d206f699960"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (6.0.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TatHWijIwB7r"
      },
      "outputs": [],
      "source": [
        "model_path = 'ruscorpora_mystem_cbow_300_2_2015.bin.gz'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqBiwzzlwE9W"
      },
      "outputs": [],
      "source": [
        "model = gensim.models.KeyedVectors.load_word2vec_format(model_path, binary=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgDxS_I6wIMh"
      },
      "outputs": [],
      "source": [
        "words = ['игра_S', 'кукла_S', 'вода_S', 'история_S']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy5v9XQQxHm1",
        "outputId": "050eb0fe-6941-444f-e052-1133fd1e005f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "СЛОВО - игра_S\n",
            "5 ближайших соседей слова:\n",
            "забава_S => 0.5167999267578125\n",
            "состязание_S => 0.5066081881523132\n",
            "поединок_S => 0.49275100231170654\n",
            "игрок_S => 0.4754316210746765\n",
            "турнир_S => 0.46379485726356506\n",
            "\n",
            "СЛОВО - кукла_S\n",
            "5 ближайших соседей слова:\n",
            "игрушка_S => 0.5909895896911621\n",
            "барби_S => 0.4864111542701721\n",
            "куколка_S => 0.4596535563468933\n",
            "марионетка_S => 0.44576260447502136\n",
            "манекен_S => 0.4457562267780304\n",
            "\n",
            "СЛОВО - вода_S\n",
            "5 ближайших соседей слова:\n",
            "вод_S => 0.6678440570831299\n",
            "водичка_S => 0.639014482498169\n",
            "влага_S => 0.5951642990112305\n",
            "водица_S => 0.5687029361724854\n",
            "струя_S => 0.5454239249229431\n",
            "\n",
            "СЛОВО - история_S\n",
            "5 ближайших соседей слова:\n",
            "биография_S => 0.5076440572738647\n",
            "литература_S => 0.502642810344696\n",
            "предыстория_S => 0.4982653260231018\n",
            "эпизод_S => 0.4979042410850525\n",
            "эпопея_S => 0.47153639793395996\n"
          ]
        }
      ],
      "source": [
        "for word in words:\n",
        "    if word in model:\n",
        "        print('\\nСЛОВО - {}'.format(word))\n",
        "        print('5 ближайших соседей слова:')\n",
        "        for word, sim in model.most_similar(positive=[word], topn=5):\n",
        "            print('{} => {}'.format(word, sim))\n",
        "    else:\n",
        "        print('Слово \"{}\" не найдено в модели'.format(word))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0RDfHMr9sgv"
      },
      "source": [
        "# Находим близость между словами и строим аналогии"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cTsFYXWxL9K",
        "outputId": "d94b9117-8d09-400f-aa70-dbdef6ca9424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.21364066\n"
          ]
        }
      ],
      "source": [
        "print(model.similarity('игра_S', 'кукла_S'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DI2D3nmtxMao",
        "outputId": "8c067d01-1874-4802-8f24-aa53a12add0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('игрушка_S', 0.5048706531524658), ('войнушка_S', 0.44554901123046875), ('бирюлька_S', 0.4163092076778412), ('серсо_S', 0.4107948839664459), ('жмурки_S', 0.38806334137916565), ('концертино_S', 0.3824155330657959), ('пинг-понг_S', 0.3785353899002075), ('барби_S', 0.3749503791332245), ('тавлея_S', 0.3726223111152649), ('пятнашки_S', 0.3697151243686676)]\n"
          ]
        }
      ],
      "source": [
        "print(model.most_similar(positive=['игра_S', 'кукла_S'], negative=['вода_S']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3dZXqKE9zrt"
      },
      "source": [
        "# Обучим word2vec на наборе данных \"fetch_20newsgroups\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIABoRcH5tWG",
        "outputId": "68047c45-0989-4911-ae44-cb8935632fa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Dict, Tuple\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from nltk import WordPunctTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOrsQ0koi-F1",
        "outputId": "aa57dd7a-36a5-4ecb-eac6-c01b008bd0e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZbwRKof5zb9"
      },
      "outputs": [],
      "source": [
        "categories = [\"rec.motorcycles\", \"rec.sport.baseball\", \"sci.electronics\",\"sci.med\"]\n",
        "newsgroups = fetch_20newsgroups(subset='train', categories=categories)\n",
        "data = newsgroups['data']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXFAWpOR6akB"
      },
      "outputs": [],
      "source": [
        "# Подготовим корпус\n",
        "corpus = []\n",
        "stop_words = stopwords.words('english')\n",
        "tok = WordPunctTokenizer()\n",
        "for line in newsgroups['data']:\n",
        "    line1 = line.strip().lower()\n",
        "    line1 = re.sub(\"[^a-zA-Z]\",\" \", line1)\n",
        "    text_tok = tok.tokenize(line1)\n",
        "    text_tok1 = [w for w in text_tok if not w in stop_words]\n",
        "    corpus.append(text_tok1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-8AkEoW6vg4",
        "outputId": "993d94c4-5ec9-44a6-b70e-158d01b02db5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['nrmendel',\n",
              "  'unix',\n",
              "  'amherst',\n",
              "  'edu',\n",
              "  'nathaniel',\n",
              "  'mendell',\n",
              "  'subject',\n",
              "  'bike',\n",
              "  'advice',\n",
              "  'organization',\n",
              "  'amherst',\n",
              "  'college',\n",
              "  'x',\n",
              "  'newsreader',\n",
              "  'tin',\n",
              "  'version',\n",
              "  'pl',\n",
              "  'lines',\n",
              "  'ummm',\n",
              "  'bikes',\n",
              "  'kx',\n",
              "  'suggest',\n",
              "  'look',\n",
              "  'zx',\n",
              "  'since',\n",
              "  'horsepower',\n",
              "  'whereas',\n",
              "  'might',\n",
              "  'bit',\n",
              "  'much',\n",
              "  'sincerely',\n",
              "  'nathaniel',\n",
              "  'zx',\n",
              "  'dod',\n",
              "  'ama'],\n",
              " ['grante',\n",
              "  'aquarius',\n",
              "  'rosemount',\n",
              "  'com',\n",
              "  'grant',\n",
              "  'edwards',\n",
              "  'subject',\n",
              "  'krillean',\n",
              "  'photography',\n",
              "  'reply',\n",
              "  'grante',\n",
              "  'aquarius',\n",
              "  'rosemount',\n",
              "  'com',\n",
              "  'grant',\n",
              "  'edwards',\n",
              "  'organization',\n",
              "  'rosemount',\n",
              "  'inc',\n",
              "  'lines',\n",
              "  'nntp',\n",
              "  'posting',\n",
              "  'host',\n",
              "  'aquarius',\n",
              "  'stgprao',\n",
              "  'st',\n",
              "  'unocal',\n",
              "  'com',\n",
              "  'richard',\n",
              "  'ottolini',\n",
              "  'writes',\n",
              "  'living',\n",
              "  'things',\n",
              "  'maintain',\n",
              "  'small',\n",
              "  'electric',\n",
              "  'fields',\n",
              "  'enhance',\n",
              "  'certain',\n",
              "  'chemical',\n",
              "  'reactions',\n",
              "  'promote',\n",
              "  'communication',\n",
              "  'states',\n",
              "  'cell',\n",
              "  'communicate',\n",
              "  'cells',\n",
              "  'nervous',\n",
              "  'system',\n",
              "  'specialized',\n",
              "  'example',\n",
              "  'perhaps',\n",
              "  'uses',\n",
              "  'true',\n",
              "  'electric',\n",
              "  'fields',\n",
              "  'change',\n",
              "  'location',\n",
              "  'time',\n",
              "  'large',\n",
              "  'organism',\n",
              "  'also',\n",
              "  'true',\n",
              "  'special',\n",
              "  'photographic',\n",
              "  'techniques',\n",
              "  'applying',\n",
              "  'external',\n",
              "  'fields',\n",
              "  'kirillian',\n",
              "  'photography',\n",
              "  'interact',\n",
              "  'fields',\n",
              "  'resistances',\n",
              "  'caused',\n",
              "  'fields',\n",
              "  'make',\n",
              "  'interesting',\n",
              "  'pictures',\n",
              "  'really',\n",
              "  'kirlian',\n",
              "  'photography',\n",
              "  'taking',\n",
              "  'pictures',\n",
              "  'corona',\n",
              "  'discharge',\n",
              "  'objects',\n",
              "  'animate',\n",
              "  'inanimate',\n",
              "  'fields',\n",
              "  'applied',\n",
              "  'objects',\n",
              "  'millions',\n",
              "  'times',\n",
              "  'larger',\n",
              "  'biologically',\n",
              "  'created',\n",
              "  'fields',\n",
              "  'want',\n",
              "  'record',\n",
              "  'biologically',\n",
              "  'created',\n",
              "  'electric',\n",
              "  'fields',\n",
              "  'got',\n",
              "  'use',\n",
              "  'low',\n",
              "  'noise',\n",
              "  'high',\n",
              "  'gain',\n",
              "  'sensors',\n",
              "  'typical',\n",
              "  'eegs',\n",
              "  'ekgs',\n",
              "  'kirlian',\n",
              "  'photography',\n",
              "  'phun',\n",
              "  'physics',\n",
              "  'type',\n",
              "  'stuff',\n",
              "  'right',\n",
              "  'soaking',\n",
              "  'chunks',\n",
              "  'extra',\n",
              "  'fine',\n",
              "  'steel',\n",
              "  'wool',\n",
              "  'liquid',\n",
              "  'oxygen',\n",
              "  'hitting',\n",
              "  'hammer',\n",
              "  'like',\n",
              "  'kirlean',\n",
              "  'setup',\n",
              "  'fun',\n",
              "  'possibly',\n",
              "  'dangerous',\n",
              "  'perhaps',\n",
              "  'pictures',\n",
              "  'diagonistic',\n",
              "  'disease',\n",
              "  'problems',\n",
              "  'organisms',\n",
              "  'better',\n",
              "  'understood',\n",
              "  'perhaps',\n",
              "  'probably',\n",
              "  'grant',\n",
              "  'edwards',\n",
              "  'yow',\n",
              "  'vote',\n",
              "  'rosemount',\n",
              "  'inc',\n",
              "  'well',\n",
              "  'tapered',\n",
              "  'half',\n",
              "  'cocked',\n",
              "  'ill',\n",
              "  'conceived',\n",
              "  'grante',\n",
              "  'aquarius',\n",
              "  'rosemount',\n",
              "  'com',\n",
              "  'tax',\n",
              "  'deferred'],\n",
              " ['liny',\n",
              "  'sun',\n",
              "  'scri',\n",
              "  'fsu',\n",
              "  'edu',\n",
              "  'nemo',\n",
              "  'subject',\n",
              "  'bates',\n",
              "  'method',\n",
              "  'myopia',\n",
              "  'reply',\n",
              "  'lin',\n",
              "  'ray',\n",
              "  'met',\n",
              "  'fsu',\n",
              "  'edu',\n",
              "  'distribution',\n",
              "  'na',\n",
              "  'organization',\n",
              "  'scri',\n",
              "  'florida',\n",
              "  'state',\n",
              "  'university',\n",
              "  'lines',\n",
              "  'bates',\n",
              "  'method',\n",
              "  'work',\n",
              "  'first',\n",
              "  'heard',\n",
              "  'newsgroup',\n",
              "  'several',\n",
              "  'years',\n",
              "  'ago',\n",
              "  'got',\n",
              "  'hold',\n",
              "  'book',\n",
              "  'improve',\n",
              "  'sight',\n",
              "  'simple',\n",
              "  'daily',\n",
              "  'drills',\n",
              "  'relaxation',\n",
              "  'margaret',\n",
              "  'corbett',\n",
              "  'authorized',\n",
              "  'instructor',\n",
              "  'bates',\n",
              "  'method',\n",
              "  'published',\n",
              "  'talks',\n",
              "  'vision',\n",
              "  'improvement',\n",
              "  'relaxation',\n",
              "  'exercise',\n",
              "  'study',\n",
              "  'whether',\n",
              "  'method',\n",
              "  'actually',\n",
              "  'works',\n",
              "  'works',\n",
              "  'actually',\n",
              "  'shortening',\n",
              "  'previously',\n",
              "  'elongated',\n",
              "  'eyeball',\n",
              "  'increasing',\n",
              "  'lens',\n",
              "  'ability',\n",
              "  'flatten',\n",
              "  'order',\n",
              "  'compensate',\n",
              "  'long',\n",
              "  'eyeball',\n",
              "  'since',\n",
              "  'myopia',\n",
              "  'result',\n",
              "  'eyeball',\n",
              "  'elongation',\n",
              "  'seems',\n",
              "  'logical',\n",
              "  'approach',\n",
              "  'correction',\n",
              "  'find',\n",
              "  'way',\n",
              "  'reverse',\n",
              "  'process',\n",
              "  'e',\n",
              "  'shorten',\n",
              "  'somehow',\n",
              "  'preferably',\n",
              "  'non',\n",
              "  'surgically',\n",
              "  'recent',\n",
              "  'studies',\n",
              "  'find',\n",
              "  'know',\n",
              "  'rk',\n",
              "  'works',\n",
              "  'changing',\n",
              "  'curvature',\n",
              "  'cornea',\n",
              "  'compensate',\n",
              "  'shape',\n",
              "  'eyeball',\n",
              "  'way',\n",
              "  'train',\n",
              "  'muscles',\n",
              "  'shorten',\n",
              "  'eyeball',\n",
              "  'back',\n",
              "  'correct',\n",
              "  'length',\n",
              "  'would',\n",
              "  'even',\n",
              "  'better',\n",
              "  'bates',\n",
              "  'idea',\n",
              "  'right',\n",
              "  'thanks',\n",
              "  'information'],\n",
              " ['mcovingt',\n",
              "  'aisun',\n",
              "  'ai',\n",
              "  'uga',\n",
              "  'edu',\n",
              "  'michael',\n",
              "  'covington',\n",
              "  'subject',\n",
              "  'buy',\n",
              "  'parts',\n",
              "  'time',\n",
              "  'nntp',\n",
              "  'posting',\n",
              "  'host',\n",
              "  'aisun',\n",
              "  'ai',\n",
              "  'uga',\n",
              "  'edu',\n",
              "  'organization',\n",
              "  'ai',\n",
              "  'programs',\n",
              "  'university',\n",
              "  'georgia',\n",
              "  'athens',\n",
              "  'lines',\n",
              "  'pricing',\n",
              "  'parts',\n",
              "  'reminds',\n",
              "  'something',\n",
              "  'chemist',\n",
              "  'said',\n",
              "  'gram',\n",
              "  'dye',\n",
              "  'costs',\n",
              "  'dollar',\n",
              "  'comes',\n",
              "  'liter',\n",
              "  'jar',\n",
              "  'also',\n",
              "  'costs',\n",
              "  'dollar',\n",
              "  'want',\n",
              "  'whole',\n",
              "  'barrel',\n",
              "  'also',\n",
              "  'costs',\n",
              "  'dollar',\n",
              "  'e',\n",
              "  'charge',\n",
              "  'almost',\n",
              "  'exclusively',\n",
              "  'packaging',\n",
              "  'delivering',\n",
              "  'chemical',\n",
              "  'particular',\n",
              "  'case',\n",
              "  'byproduct',\n",
              "  'cost',\n",
              "  'almost',\n",
              "  'nothing',\n",
              "  'intrinsically',\n",
              "  'michael',\n",
              "  'covington',\n",
              "  'associate',\n",
              "  'research',\n",
              "  'scientist',\n",
              "  'artificial',\n",
              "  'intelligence',\n",
              "  'programs',\n",
              "  'mcovingt',\n",
              "  'ai',\n",
              "  'uga',\n",
              "  'edu',\n",
              "  'university',\n",
              "  'georgia',\n",
              "  'phone',\n",
              "  'athens',\n",
              "  'georgia',\n",
              "  'u',\n",
              "  'amateur',\n",
              "  'radio',\n",
              "  'n',\n",
              "  'tmi'],\n",
              " ['tammy',\n",
              "  'vandenboom',\n",
              "  'launchpad',\n",
              "  'unc',\n",
              "  'edu',\n",
              "  'tammy',\n",
              "  'vandenboom',\n",
              "  'subject',\n",
              "  'sore',\n",
              "  'spot',\n",
              "  'testicles',\n",
              "  'nntp',\n",
              "  'posting',\n",
              "  'host',\n",
              "  'lambada',\n",
              "  'oit',\n",
              "  'unc',\n",
              "  'edu',\n",
              "  'organization',\n",
              "  'university',\n",
              "  'north',\n",
              "  'carolina',\n",
              "  'extended',\n",
              "  'bulletin',\n",
              "  'board',\n",
              "  'service',\n",
              "  'distribution',\n",
              "  'na',\n",
              "  'lines',\n",
              "  'husband',\n",
              "  'woke',\n",
              "  'three',\n",
              "  'days',\n",
              "  'ago',\n",
              "  'small',\n",
              "  'sore',\n",
              "  'spot',\n",
              "  'spot',\n",
              "  'size',\n",
              "  'nickel',\n",
              "  'one',\n",
              "  'testicles',\n",
              "  'bottom',\n",
              "  'side',\n",
              "  'knots',\n",
              "  'lumps',\n",
              "  'little',\n",
              "  'sore',\n",
              "  'spot',\n",
              "  'says',\n",
              "  'reminds',\n",
              "  'bruise',\n",
              "  'feels',\n",
              "  'recollection',\n",
              "  'hitting',\n",
              "  'anything',\n",
              "  'like',\n",
              "  'would',\n",
              "  'cause',\n",
              "  'bruise',\n",
              "  'asssures',\n",
              "  'remember',\n",
              "  'something',\n",
              "  'like',\n",
              "  'clues',\n",
              "  'might',\n",
              "  'somewhat',\n",
              "  'hypochondriac',\n",
              "  'sp',\n",
              "  'sure',\n",
              "  'gonna',\n",
              "  'die',\n",
              "  'thanks',\n",
              "  'opinions',\n",
              "  'expressed',\n",
              "  'necessarily',\n",
              "  'university',\n",
              "  'north',\n",
              "  'carolina',\n",
              "  'chapel',\n",
              "  'hill',\n",
              "  'campus',\n",
              "  'office',\n",
              "  'information',\n",
              "  'technology',\n",
              "  'experimental',\n",
              "  'bulletin',\n",
              "  'board',\n",
              "  'service',\n",
              "  'internet',\n",
              "  'launchpad',\n",
              "  'unc',\n",
              "  'edu']]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "corpus[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLEebm1K7L41",
        "outputId": "1692e5b2-56e7-484f-b8cb-71a5eb152732"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6.05 s, sys: 68.3 ms, total: 6.12 s\n",
            "Wall time: 4.49 s\n"
          ]
        }
      ],
      "source": [
        "%time model_imdb = word2vec.Word2Vec(corpus, workers=4, min_count=10, window=10, sample=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klyXfeAR7SeB",
        "outputId": "a8cfc4ae-edfa-458c-b8ac-61b9b2b4a8fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('work', 0.9928374290466309), ('using', 0.9901800751686096), ('want', 0.989675760269165), ('circuits', 0.9867829084396362), ('circuit', 0.985724925994873)]\n"
          ]
        }
      ],
      "source": [
        "# Проверим, что модель обучилась\n",
        "print(model_imdb.wv.most_similar(positive=['find'], topn=5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjM2Ehr-7W0K"
      },
      "outputs": [],
      "source": [
        "def sentiment_2(v, c):\n",
        "    model = Pipeline(\n",
        "        [(\"vectorizer\", v), \n",
        "         (\"classifier\", c)])\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print_accuracy_score_for_classes(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yUJ1Ynz_2DJ"
      },
      "source": [
        "# Проверка качества работы модели word2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cL1m4h3M7eMo"
      },
      "outputs": [],
      "source": [
        "class EmbeddingVectorizer(object):\n",
        "    '''\n",
        "    Для текста усредним вектора входящих в него слов\n",
        "    '''\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.size = model.vector_size\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return np.array([np.mean(\n",
        "            [self.model[w] for w in words if w in self.model] \n",
        "            or [np.zeros(self.size)], axis=0)\n",
        "            for words in X])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNEtVYom7iCJ"
      },
      "outputs": [],
      "source": [
        "def accuracy_score_for_classes(\n",
        "    y_true: np.ndarray, \n",
        "    y_pred: np.ndarray) -> Dict[int, float]:\n",
        "    \"\"\"\n",
        "    Вычисление метрики accuracy для каждого класса\n",
        "    y_true - истинные значения классов\n",
        "    y_pred - предсказанные значения классов\n",
        "    Возвращает словарь: ключ - метка класса, \n",
        "    значение - Accuracy для данного класса\n",
        "    \"\"\"\n",
        "    # Для удобства фильтрации сформируем Pandas DataFrame \n",
        "    d = {'t': y_true, 'p': y_pred}\n",
        "    df = pd.DataFrame(data=d)\n",
        "    # Метки классов\n",
        "    classes = np.unique(y_true)\n",
        "    # Результирующий словарь\n",
        "    res = dict()\n",
        "    # Перебор меток классов\n",
        "    for c in classes:\n",
        "        # отфильтруем данные, которые соответствуют \n",
        "        # текущей метке класса в истинных значениях\n",
        "        temp_data_flt = df[df['t']==c]\n",
        "        # расчет accuracy для заданной метки класса\n",
        "        temp_acc = accuracy_score(\n",
        "            temp_data_flt['t'].values, \n",
        "            temp_data_flt['p'].values)\n",
        "        # сохранение результата в словарь\n",
        "        res[c] = temp_acc\n",
        "    return res\n",
        "\n",
        "def print_accuracy_score_for_classes(\n",
        "    y_true: np.ndarray, \n",
        "    y_pred: np.ndarray):\n",
        "    \"\"\"\n",
        "    Вывод метрики accuracy для каждого класса\n",
        "    \"\"\"\n",
        "    accs = accuracy_score_for_classes(y_true, y_pred)\n",
        "    if len(accs)>0:\n",
        "        print('Метка \\t Accuracy')\n",
        "    for i in accs:\n",
        "        print('{} \\t {}'.format(i, accs[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLZ9TMCd7ksg"
      },
      "outputs": [],
      "source": [
        "# Обучающая и тестовая выборки\n",
        "boundary = 1500\n",
        "X_train = corpus[:boundary] \n",
        "X_test = corpus[boundary:]\n",
        "y_train = newsgroups['target'][:boundary]\n",
        "y_test = newsgroups['target'][boundary:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBvQx4dv73ls",
        "outputId": "d8bc4e51-8c88-4f6a-974f-3b437901552e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Метка \t Accuracy\n",
            "0 \t 0.8201754385964912\n",
            "1 \t 0.9271844660194175\n",
            "2 \t 0.7614678899082569\n",
            "3 \t 0.7324561403508771\n"
          ]
        }
      ],
      "source": [
        "sentiment_2(EmbeddingVectorizer(model_imdb.wv), LogisticRegression(C=5.0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnUKW0uhFBJa"
      },
      "source": [
        "Качество модели лучше у CountVectorizer"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Lab5_MMO.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}